模型结构

* MLP
* Wide&Deep
* 双塔模型

冷启动：用户/物品/系统首次使用平台

embedding部分的难点在于存储和检索(sparse net)。DNN这部分主要是稠密计算(dense net)。

RPC:远程过程调用 计算机通信协议 允许程序调用位于另一台计算机 

异步训练可能会牺牲一定的准确性 某些节点基于旧的参数进行计算，导致梯度更新并不完全准确，引入噪声，影响收敛路径

心跳：其核心原理是节点定期向调度器（Scheduler）发送信号（即心跳包），以证明其存活且正常工作。

多级前缀树

pipeline

**Batch Normalization（批量归一化**：加速神经网络训练并提升训练稳定性，标准化神经网络每一层的输入分布，缓解深度网络训练中的内部协变量偏移。提高模型收敛速度和泛化能力

前向传播和后向传播

先有个一个条目

记录 user_id  等等各种特征 

然后 主动fea  一共有m种 有n纬度 就是m行n列  

被动fea

交叉fea

模型确定是在shadow-tf-base里面的    embedding也在里面 选取部分的  

然后有个总表记录user等 这个是不是就是fid 不是  这个是unordered_map的key     然后去拿这每个fea对应的一行 拼接起来成一个表

再去二分进行01判断  训练完后是给的模型loss最小的  输入一组参数后最后给的是是否会点击的判断

比如6亿个用户 组成的信息量太多了 这个时候就会把数据存储 用hash去分布在不同的服务器上 PS

ps负责梯度更新 梯度汇聚 embedding更新

worker负责前向传播和后向传播 异步是不等worker的

过程 先embedding  

hdfs    离线训练

kafka    在线或实时训练



worker推数据给ps  worker生产者  ps汇总后 worker拉数据 消费者  





前向传播



后向传播





### 双塔召回

    import torch
    import torch.nn as nn
    
    class TwoTowerModel(nn.Module):
        def __init__(self, user_dim, item_dim, emb_dim):
            super().__init__()
    				self.user_tower = nn.Sequential(
                nn.Linear(user_dim, 256),
                nn.ReLU(),
                nn.Linear(256, emb_dim)
            )
    				self.item_tower = nn.Sequential(
                nn.Linear(item_dim, 256),
                nn.ReLU(),
                nn.Linear(256, emb_dim)
            )
    def forward(self, user_feat, item_feat):
        user_emb = self.user_tower(user_feat)  # (B, D)
        item_emb = self.item_tower(item_feat)  # (B, D)
        # 相似度计算（内积）
        scores = torch.matmul(user_emb, item_emb.T)  # (B, B)
        return scores



PS二阶段拆开是为了错开计算和load 做了一个类似pipeline的操作

把主动方 被动方 交叉特征 和online 推理模型 分开

主动方只有一个用户 

被动方每次更新都要重新更新参数  S2用来存临时的参数  

RPS是用来更新模型的 粗排很粗略 用到的特征很少 RPS用来精排 灵活度更高  既要更新统计特征也要更新模型权重  

kafka   消息队列 如果有消息传入 更新



PS-Predict-Server就是PSserver

PredictEmb-Server是被动方的那个模型？？

PS-S2-EMB 被动方刷新之后更新的那个缓存

PS-Predict-ACT 是主动方那个模型 ？



1、**数据流Pipeline化**：

- 用户请求先触发粗排，粗排结果缓存后异步触发精排，降低端到端延迟。
- 通过消息队列（如Kafka）解耦阶段间的依赖，实现异步处理。

##### 2、交叉特征与模型分离

- **粗排阶段**：仅使用简单特征（用户ID、物品ID、基础统计特征）。
- **精排阶段**：引入复杂交叉特征（用户-物品历史交互、注意力权重）。
- 在线推理分离
  - 粗排和精排模型独立部署，粗排模型轻量化（如TensorRT加速），精排模型支持复杂计算（如TF Serving）。



破除其余的 不用关键词搜索 只需要完整的语义理解

bucket里面存的是不同feature和feature不同的特征值对应的embedding

slot特征code  code的前n位

step_uuid是用来保证同步的    uuid是同一次训练一样

triton算子

2.5版本的torch

qps：每秒查询数

长尾效应

精排

粗排



|                  | 搜索系统（Search）          | 推荐系统（Recommendation）           |
| ---------------- | --------------------------- | ------------------------------------ |
| **输入**         | 用户 query（主动）          | 用户画像（被动），行为上下文         |
| **目标**         | 精准命中用户的搜索意图      | 发掘潜在感兴趣内容（探索+利用）      |
| **召回源**       | 多来自用户 query + 倒排索引 | 多来自用户历史行为 + 热门/兴趣图谱   |
| **匹配方式**     | query 与文档向量相似度匹配  | 用户 Embedding 与内容 Embedding 计算 |
| **在线响应时间** | 极端敏感（几十 ms）         | 稍宽松一些（百 ms）                  |

搜索要对一个key里面多做几种释义，比如苹果，苹果里面也许有各种各样的种类，有的人可能想要一些不一样的。如果模型始终高度重复、固化、会让模型走偏，变成马太效应。

但推荐天然就更加倾向于对多样性和新颖性做要求，这种倾向更加明显。

![img](https://pic3.zhimg.com/v2-52d137b54c2aa659b3ae8eb856873e74_r.jpg)

搜推需要从数值信息中推理到最终结果 

1、输入阶段 (多路特征) 

2、embedding层（稀疏->稠密）多个filed转化成多个embedding 这个embedding表也是要训练出来的 然后再拼接起来 

3、多层DNN（密集全连接层）

4、输出层（预测点击/转化率）

主路召回：主要依赖“用户画像+内容embedding+相似性“

旁路召回：不太看重用户画像，走规则、热度、多样性、新颖性、长尾补全、提升整体覆盖率、冷启动、用户探索感

保送召回：一定进最终候选集的召回内容     whitelist  通常只保送进粗排



## 模型流程

一个样本对应多个fid  根据fid的值去embedding表拿数据  成稠密固定维度矩阵

embedding后送入召回 

#### 召回

召回：ANN检索  衡量相似度  向量检索的策略 基本是衡量相似度

这个时候进入召回的有很多  主召回(topk)  旁召回 保送召回 合并起来 送入粗排

召回池 = TopK ANN items(内积、欧式距离、cosine) + 热门 + 冷启 + 保送内容

然后根据粗排需要的feature 继续embedding   embedding成一张表然后送入粗排 

每次不一样 需要补齐特征 根据item_id

召回返回item_id  粗排返回item_id的列表 每次都差不多差十倍

###### 小小过滤一下：多路合并 去重 违反各种规则的筛掉

#### 粗排

二阶段粗排  可以利用一阶段快速压缩召回量 3k->1k

一阶段：

LR/GBDT/Rule-Based Filter

**LR**：特征必须是稀疏离散型，非常快  解释性很好 

gpt说特征之间的联系主要是保存在模型里，而不是单个的embedding表里 那为啥LR

也很好理解 LR这个公式就是模型 公式前面的系数就是权重 所以从这个数理表达式来看确实无法表达复杂关系

**Gradient Boosted Decision Tree**(梯度提升树)：弱决策树按残差逐步优化  回归/分类器  高性能版本XGBoost

**Rule-Based Filter**(规则过滤)：手写规则

二阶段：

更精细一些

shallow DNN/FM

shallow DNN：

1-2层mlp 在推荐中通常和FM 或 Wide 结合（比如 Wide & Deep）

***Wide & Deep*** 前者负责记忆 后者负责泛化  

**Wide**
$$
logit = W^T[X, \phi(X)]+b
$$
X是原始特征向量 one-hot编码

ϕ(X)是人工构造的交叉特征向量，每个只有当组成它的所有xi同时为1时才为1，否则为0   

经过sigmoid激活，输出概率
$$
\hat y(概率) = \sigma(logit)
$$
**Deep**





分二阶段应该是出于效率设计

打分指标 CTR粗略估计 **打分要求快速    快**

**加速**：

1、做kv缓存系统？？

2、二阶段必修支持batch输入 批量打分

3、复用embedding表

#### 精排 

精排模型常见结构 DeepFM / Wide&Deep

精准 CTR / CVR / 订单额等

DIN

DIEN/ DSIN/ MIND

Multi-Tower

transformer-based Ranking 

打分准



***

#### details

| 点             | 内容                                                  |
| -------------- | ----------------------------------------------------- |
| 模型部署       | 通常部署在 GPU / 高性能 CPU，支持 batch 推理          |
| 特征一致性保障 | 强依赖 Feature Store，保证 online/offline 一致        |
| 多任务建模     | 同时预测 CTR、CVR、订单额、播放完成率等，提升学习能力 |
| 延迟控制       | 推理时长需 <10ms，一般在 300 item 上做批量打分        |

FM(Factorization Machine 因子分解机)  :所有特征之间两两组合都能建交叉关系

*池化出现在什么时候：max和平均*

用户侧的行为序列建模，和时间相关的序列向量 

因果推断：

**数据采样如何曝光偏置 提升训练样本公平性**？

给每个曝光样本打一个权重，越不容易被推荐的item越值得放大 

或者在样本中加入负样本  模拟用户会点击但是没曝光的样本 有点引入惩罚项？？？

**怎么负样本补充**

`is_exposed` 是 **训练用的 mask/control 特征** 控制结构

`exposure_prob` 是 IPW 权重用（可当作 loss 加权 or embedding feature）

**上面那两句话是什么意思**

可以作为featrue查embedding，可以one-hot拼，也可以控制分支结构(mask机制 用于控制结构走向)  可以决定改样本   该不该进 loss / 要不要反向传播 / 权重多大

**mask怎么理解**

* Causal Mask    llm常见

* Behavioral Sequence Mask  该掩码出现在推荐系统的序列建模中，处理用户行为序列的不定长和填充问题：有些模型在对用户历史行为序列建模时，序列长短不一，padding，再搞一个mask矩阵表识padding，可能后续在此处不更新梯度
* Structural Control Mask  结构控制掩码决定网络中哪些模块、神经元或连接被激活等，选择训练或推理模型结构，网络剪枝；掩码也可以作为训练参数，动态推理；结构化稀疏/剪枝

***

#### 深度学习理论知识

sigmoid激活函数:

silu激活函数:

softmax:

Rmsnorm:

正则化：

* L1正则化  
  $$
  L_1 = \sum|w_i|
  $$
  强制让某些权重变成0  倾向稀疏

* L2正则化

$$
L_2 = \sum w_i^2
$$

​	抑制过大，防止梯度爆炸、过拟合
